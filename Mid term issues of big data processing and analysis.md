##  题目一

> 从统计学的角度阐述大数据的定义以及从学习算法训练的角度探讨大数据产生的原因

###  答

> 1. 大数据的定义
>
> 大数据是能够产生大规模样本的随机试验的样本空间或总体
>
> 所谓随机试验，就是在相同条件下可重复，试验结果全部明确可知的数学事件
>
> 样本空间即为随机试验的全部可能出现的试验结果的集合
>
> 综上所述，如果一个随机试验所能产生试验结果的集合是大规模的，那么这个集合就是大数据本身
>
> 2. 大数据产生的原因
>
> 模型的训练精度与模型本身的参数量和学习数据量是有关的，也就是说参数越多，样本越多，就越有可能训练出效果好的模型
>
> 随着深度学习的兴起，模型的训练对于数据量的要求越来越大，如果数据能大到能够逼近某个产生大规模数据的随机试验的总体的话就完全足够了，这便是大数据产生的原因之一

##  题目二

> 举例说明大数据分布式存储系统中所使用的里德-所罗门纠错码（RS码）容错机制的基本原理，并探讨如何缓解数据恢复过程中的失真问题

###  答

> 1. 举例说明RS码容错机制的基本原理
>
> 利用N个数据块对应的M个校验块去重构出错的原始数据块与校验块
>
> 例子
>
> 2. 缓解失真问题
>
> 由于RS码能够容忍m个数据块（校验块个数为m）的丢失，那么只要校验块的个数足够多，接收器能接受到足够的数据使其恢复，就能缓解数据恢复时的失真

##  题目三

> 对于给定的含有N个样本的记录型大数据集D，我们将其切分为k个数据子集
> $$
> D_1,D_2,L,D_K
> $$
> 样本规模分别为
> $$
> N_1,N_2,L,N_k
> $$
> 那么我们如何基于
> $$
> D_1,D_2,L,D_K
> $$
> 完成对D的异常点检测，请详述你的设计过程

###  答

> 要由子块的数据来完成对数据整体的异常点检测，我们需要得知（估计）数据整体的概率分布，我们可以按照子块的规模进行成比例的随机抽样，将所有子块的抽样所得到得样本点混合，这个数据集所服从的概率分布应大致与整体的概率分布相似，这时我们即可根据这个概率分布来进行异常值检测，由于这个分布不一定是正态分布，所以我们用核密度估计方法来估计对应的边缘概率分布函数，将新的样本点带入，若函数的值很小，则为异常点，以上便为我设计的异常检测算法

##  题目四

> 对于给定的大数据集D，现有其对应的HDFS数据块
> $$
> D_1,D_2,L,D_K
> $$
> 如何基于D的HDFS数据块获得D对应的RSP数据块，请详述具体的实现过程，可结合图示说明。
>
> （注：RSP数据块是在给定的显著性水平下与大数据保持概率分布一致性的数据子集）

###  答

> 1. 对每个HDFS数据块，进行块内的shuffling，然后将每个shuffling之后的数据块内部分成M块，第i个RSP数据块（共有M个）即为所有shuffling之后的HDFS数据块内部对应位置i处的数据块的并集

